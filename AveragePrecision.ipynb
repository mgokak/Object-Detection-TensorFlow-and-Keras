{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq41ilvmpgxz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
        "block_plot = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute intersection over union of detected boxes with GTs.\n",
        "def get_iou(predicted_dbox, ground_truth_dboxes):\n",
        "    \"\"\"\n",
        "        Calculates IoU (Jaccard index) of two detection boxes:\n",
        "            predicted_dbox ∩ ground_truth_dbox / (area(predicted_dbox) +\n",
        "            area(ground_truth_dbox) - predicted_dbox ∩ ground_truth_dbox)\n",
        "\n",
        "        Parameters:\n",
        "            Coordinates of detection boxes are supposed to be in the following form: [x1, y1, x2, y2]\n",
        "            predicted_dbox: [tensor] predicted detection boxe\n",
        "            ground_truth_dboxes: [tensor] ground truth detection boxes\n",
        "\n",
        "        Return value:\n",
        "            overlap area\n",
        "    \"\"\"\n",
        "    # Get coordinates of boxes to prepare overlap data.\n",
        "    xmin = tf.math.maximum(ground_truth_dboxes[:, 0], predicted_dbox[0])\n",
        "    ymin = tf.math.maximum(ground_truth_dboxes[:, 1], predicted_dbox[1])\n",
        "    xmax = tf.math.minimum(ground_truth_dboxes[:, 2], predicted_dbox[2])\n",
        "    ymax = tf.math.minimum(ground_truth_dboxes[:, 3], predicted_dbox[3])\n",
        "\n",
        "    width = tf.math.maximum(xmax - xmin + 1., 0.0)\n",
        "    height = tf.math.maximum(ymax - ymin + 1., 0.0)\n",
        "    intersection_area = width * height\n",
        "\n",
        "    # Calculate the union value.\n",
        "    union = ((predicted_dbox[2] - predicted_dbox[0] + 1.) * (predicted_dbox[3] - predicted_dbox[1] + 1.) +\n",
        "             (ground_truth_dboxes[:, 2] - ground_truth_dboxes[:, 0] + 1.) *\n",
        "             (ground_truth_dboxes[:, 3] - ground_truth_dboxes[:, 1] + 1.) - intersection_area)\n",
        "\n",
        "    return intersection_area / union"
      ],
      "metadata": {
        "id": "rEWcAYlXBk-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if intersections of predicted and ground-truth boxes are greater than predefined threshold.\n",
        "def check_iou_threshold(predicted_dbox, ground_truth_dboxes, intersection_threshold):\n",
        "    \"\"\"\n",
        "        Get the predictions with an appropriate IoU area for further true positives computations\n",
        "\n",
        "        Parameters:\n",
        "        predicted_dboxes: predicted by the detector detection boxes\n",
        "        ground_truth_dboxes: ground truth\n",
        "        intersection_threshold: IoU threshold\n",
        "\n",
        "        Return value:\n",
        "            tensor with the following values:\n",
        "                    True - if the IoU passed defined threshold\n",
        "                    False - if the IoU did not pass defined threshold\n",
        "            index of the maximum IoU value\n",
        "    \"\"\"\n",
        "    intersection_over_union = get_iou(predicted_dbox, ground_truth_dboxes)\n",
        "    return  (\n",
        "                tf.math.reduce_max(intersection_over_union) >= intersection_threshold,\n",
        "                tf.math.argmax(intersection_over_union)\n",
        "            )"
      ],
      "metadata": {
        "id": "XM7NcXIgBy_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_groundtruth_prediction_boxes(ground_truths, predictions):\n",
        "    \"\"\"\n",
        "    \"Plots ground truth and prediction bounding boxes\"\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "    gt_bboxes (list): a list of ground truths.\n",
        "                      Format:\n",
        "                      [\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max] (tf.Variable)],\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max] (tf.Variable)],\n",
        "                                         :\n",
        "                                         :\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max] (tf.Variable)]\n",
        "\n",
        "                      ]\n",
        "\n",
        "    pred_bboxes (list): a list of detected bounding box data containing ImageID, boxes, conf. scores.\n",
        "                        Format:\n",
        "                        [\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max](tf.Variable), prob_1(tf.Variable)],\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max](tf.Variable), prob_2(tf.Variable)],\n",
        "                                                     :\n",
        "                                                     :\n",
        "                          [Image_ID(str), [x_min, y_min, x_max, y_max](tf.Variable), prob_n(tf.Variable)]\n",
        "\n",
        "                        ]\n",
        "    \"\"\"\n",
        "\n",
        "    box_data = [ground_truths, predictions]\n",
        "\n",
        "    sorted_ind = [i for i,_ in sorted(enumerate(predictions), key=lambda conf: conf[1][2], reverse=True)]\n",
        "\n",
        "\n",
        "    colors = ['b', 'r']\n",
        "    label_prefix = ['g-truth', 'pred']\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "\n",
        "    for boxtype_i, boxes in enumerate(box_data):\n",
        "\n",
        "        dbox_data = tf.stack([box[1] for box in boxes])\n",
        "\n",
        "        width = dbox_data[:, 2] - dbox_data[:, 0] + 1\n",
        "        height = dbox_data[:, 3] - dbox_data[:, 1] + 1\n",
        "\n",
        "        for i in range(tf.shape(dbox_data)[0]):\n",
        "\n",
        "            # Ground Truths.\n",
        "            if boxtype_i == 0:\n",
        "                index = i\n",
        "                label = '{}. {}'.format(index, label_prefix[0])\n",
        "\n",
        "            # Detections.\n",
        "            else:\n",
        "                index = sorted_ind[i]\n",
        "                label = '{0}. {1}({2:.2})'.format(index, label_prefix[1], predictions[index][2].numpy())\n",
        "\n",
        "\n",
        "            x_label = dbox_data[index, 0] + 8\n",
        "            y_label = dbox_data[index, 3] - 10\n",
        "\n",
        "            ax.add_patch(\n",
        "                patches.Rectangle(\n",
        "                    (dbox_data[index, 0], dbox_data[index, 1]),\n",
        "                    width[index],\n",
        "                    height[index],\n",
        "                    fill=False,      # remove background\n",
        "                    color=colors[boxtype_i],\n",
        "                    linewidth = 3,\n",
        "            )\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "            ax.text(x_label, y_label, label, color=colors[boxtype_i],\n",
        "                    bbox=dict(facecolor='none', edgecolor=colors[boxtype_i]))\n",
        "\n",
        "\n",
        "    plt.xticks(range(0, 1550, 50))\n",
        "    plt.yticks(range(0, 1050, 50))\n",
        "\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.gca().axis('tight')\n",
        "    plt.show(block=block_plot)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "vsXGjiamCZgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bounding boxes / detection\n",
        "ground_truths = [\n",
        "                 ['1', tf.Variable([ 100, 500,  300, 950], dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([ 350, 550,  570, 930], dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([ 600, 200,  850, 600], dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([ 900, 10,  1100, 380], dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([ 980, 500, 1200, 950], dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([1250, 300, 1470, 800], dtype=tf.float32)],\n",
        "                ]\n",
        "\n",
        "# bounding boxes / detection\n",
        "detections = [\n",
        "               ['1', tf.Variable([ 120, 450,  325, 900], dtype=tf.float32), tf.Variable(.67)],\n",
        "               ['1', tf.Variable([ 340, 500,  580, 970], dtype=tf.float32), tf.Variable(.87)],\n",
        "               ['1', tf.Variable([ 620, 300,  870, 800], dtype=tf.float32), tf.Variable(.65)],\n",
        "               ['1', tf.Variable([ 820, 180, 1170, 440], dtype=tf.float32), tf.Variable(.56)],\n",
        "               ['1', tf.Variable([1000, 550, 1220, 980], dtype=tf.float32), tf.Variable(.89)],\n",
        "               ['1', tf.Variable([1300, 320, 1450, 750], dtype=tf.float32), tf.Variable(.99)],\n",
        "               ['1', tf.Variable([ 350, 100,  580, 450], dtype=tf.float32), tf.Variable(.51)],\n",
        "               ['1', tf.Variable([ 950, 490, 1180, 960], dtype=tf.float32), tf.Variable(.83)],\n",
        "             ]"
      ],
      "metadata": {
        "id": "xsDYrlBpFjC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the indices of sorted (decreasing order) prediction confidence.\n",
        "# These indices will be used to prioritize detection.\n",
        "s_ind = [i for i,_ in sorted(enumerate(detections), key=lambda conf: conf[1][2], reverse=True)]\n",
        "\n",
        "all_gt_dboxes = tf.stack([gt[1] for gt in ground_truths])\n",
        "\n",
        "# The IoU threshold.\n",
        "iou_thres = 0.5\n",
        "\n",
        "for i, s_index in enumerate(s_ind):\n",
        "    pred_conf = detections[s_index][2].numpy()\n",
        "\n",
        "    print('Predicted Bounding Box index: {0}, prob: {1:0.3}'.format(s_index, pred_conf))\n",
        "    qualified_iou_thres, gt_index = check_iou_threshold(detections[s_index][1], all_gt_dboxes,\n",
        "                                                        intersection_threshold=iou_thres)\n",
        "    print('Is any g-truth box has IoU more than {0:.2}: {1}'.format(iou_thres, qualified_iou_thres))\n",
        "    print('The g-truth that has maximum IoU with pred-box, {0}({1:.2}): {2}'.format(s_index, pred_conf,\n",
        "                                                                                    gt_index))\n",
        "\n",
        "    print('------'*10)"
      ],
      "metadata": {
        "id": "RB6_5uFgFldL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match(sorted_ind, detections, gts_per_image, intersection_threshold, debug=False):\n",
        "    \"\"\"\n",
        "    match detected boxes with ground-truth boxes.\n",
        "\n",
        "    Parameters:\n",
        "        sorted_ind: Indicies corresponds to the confidence score in decreasing order.\n",
        "\n",
        "        detections: Contains info on the detections predicted by the model.\n",
        "\n",
        "        gts_per_image: A dictionary which maintains all ground truths based on ImageID.\n",
        "\n",
        "        intersection_threshold: IoU threshold.\n",
        "\n",
        "        debug: boolean, to print logs. default is false.\n",
        "\n",
        "    Return value:\n",
        "        true_positives: A tensor of boolean values\n",
        "        false_positives: A tensor of boolean values\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Define true positives and false positives TF tensors.\n",
        "    true_positives = tf.Variable(tf.zeros((len(sorted_ind)), dtype=tf.float64))\n",
        "    false_positives = tf.Variable(tf.zeros((len(sorted_ind)), dtype=tf.float64))\n",
        "\n",
        "    # Prepare the boolean list for further check whether the object for that particular image\n",
        "    # has been already detected.\n",
        "    # So we create a dictionary: 'is_obj_already_detected' that maintains this boolean list based on the ImageID.\n",
        "    is_obj_already_detected = {key: np.full((len(gts_per_image[key]), ), False) for key in gts_per_image}\n",
        "\n",
        "    # For each box decide if it is a true positive or a false positive.\n",
        "    for i, box_num in enumerate(sorted_ind):\n",
        "\n",
        "        # Get the detection (a list containing ImageID, BBox and conf. score) based on sorted_ind.\n",
        "        det = detections[box_num]\n",
        "\n",
        "        # Get the detected BBox coordinates.\n",
        "        predicted_dbox = det[1]\n",
        "\n",
        "        # Stack all ground truth bboxes based on the ImageID from det.\n",
        "        all_gt_dboxes = tf.stack([gt[1] for gt in gts_per_image[det[0]]])\n",
        "\n",
        "        is_pass_threshold, max_iou_index = check_iou_threshold(\n",
        "            predicted_dbox, all_gt_dboxes, intersection_threshold\n",
        "        )\n",
        "        # Note that \"true_positives\" and \"false_positives\" are updated with \"i\" and not with sorted index.\n",
        "        # This is being done so that higher confident detections should be prioritized.\n",
        "        if is_pass_threshold and not is_obj_already_detected[det[0]][max_iou_index]:\n",
        "            true_positives[i].assign(1.0)\n",
        "            is_obj_already_detected[det[0]][max_iou_index] = True\n",
        "            if debug:\n",
        "                print('Predicted box no {} is true positive.'.format(box_num))\n",
        "        else:\n",
        "            false_positives[i].assign(1)\n",
        "            if debug:\n",
        "                print('Predicted box no {} is false positive.'.format(box_num))\n",
        "\n",
        "    return true_positives, false_positives"
      ],
      "metadata": {
        "id": "6_ontwhKFoFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gts_per_image = defaultdict(list)\n",
        "for gt in ground_truths:\n",
        "    gts_per_image[gt[0]].append(gt)\n",
        "\n",
        "t_positive, f_positive = match(sorted_ind=s_ind,\n",
        "                               detections=detections,\n",
        "                               gts_per_image=gts_per_image,\n",
        "                               intersection_threshold=iou_thres,\n",
        "                               debug=True)\n",
        "\n",
        "print('\\nTrue positives: {}, \\nFalse positives: {}'.format(t_positive.numpy(), f_positive.numpy()))"
      ],
      "metadata": {
        "id": "Uo7pZ7aEFtY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The core class for running average precision pipeline.\n",
        "class AveragePrecisionEvaluator:\n",
        "    def __init__(self, intersection_threshold=0.5, use_07_metric=False, points_number=11, debug=False):\n",
        "\n",
        "        # Keep track of all ground truths per ImageID.\n",
        "        self.gts = defaultdict(list)\n",
        "        # Create 11 recall points, on these points precesion will be interpolated.\n",
        "        self.recall_levels = tf.cast(tf.linspace(0., 1., points_number), dtype=tf.float64)\n",
        "        # Predefined intersection threshold.\n",
        "        self.intersection_threshold = intersection_threshold\n",
        "        # Init recalls and precisions to fill them with approprite values in run_ap_calculation method.\n",
        "        self.recalls = None\n",
        "        self.precisions = None\n",
        "        # Init average precision for futher computation\n",
        "        self.average_precision = 0.\n",
        "        self.true_positives = None\n",
        "        self.false_positives = None\n",
        "        self.false_negatives = None\n",
        "        self.use_07_metric = use_07_metric\n",
        "        self.debug = debug\n",
        "\n",
        "        self.precision_levels = tf.Variable(tf.zeros((points_number), dtype=tf.float64))\n",
        "\n",
        "\n",
        "    # calculate ap\n",
        "    def run_ap_calculation(self, detections, ground_truths):\n",
        "        \"\"\"\n",
        "            Initiate AP calculation process\n",
        "\n",
        "            Parameters:\n",
        "\n",
        "                detections: Contains info on the detections predicted by the model.\n",
        "                            Each detection is a list of ImageID(str), BBox(tf.Variable)\n",
        "                            and conf. score(tf.Variable)\n",
        "\n",
        "                ground_truths: Contains info on the ground truth objects.\n",
        "                               Each ground truth is a list of ImageID(str), BBox(tf.Variable)\n",
        "\n",
        "            Return value:\n",
        "                VOC mean average precision\n",
        "        \"\"\"\n",
        "        # Sort predicted_dboxes based on their confidence scores\n",
        "        sorted_ind = [i for i,_ in sorted(enumerate(detections), key=lambda conf: conf[1][2], reverse=True)]\n",
        "\n",
        "        # Initialize true positives and false positives TF tensors with 0 for each detected object.\n",
        "        true_positives = tf.Variable(tf.zeros((len(sorted_ind)), dtype=tf.float64))\n",
        "        false_positives = tf.Variable(tf.zeros((len(sorted_ind)), dtype=tf.float64))\n",
        "\n",
        "        if len(ground_truths) == 0:\n",
        "            false_positives = tf.Variable(tf.ones((len(sorted_ind)), dtype=tf.float64))\n",
        "\n",
        "        else:\n",
        "            for g in ground_truths:\n",
        "                self.gts[g[0]].append(g)\n",
        "            # Get true positives and false positives TF tensors.\n",
        "            true_positives, false_positives = match(\n",
        "                sorted_ind, detections, self.gts, self.intersection_threshold\n",
        "            )\n",
        "\n",
        "        # Get true positives cumulative sum to obtain its value.\n",
        "        self.true_positives = tf.math.cumsum(true_positives, axis=0)\n",
        "\n",
        "        # Get false positives cumulative sum to obtain its value.\n",
        "        self.false_positives = tf.math.cumsum(false_positives, axis=0)\n",
        "\n",
        "\n",
        "        # Calculate precisions.\n",
        "        self.precisions = self.true_positives / (\n",
        "            self.false_positives + self.true_positives + np.finfo(float).eps\n",
        "        )\n",
        "\n",
        "        # Calculate recalls.\n",
        "        self.recalls = self.true_positives / len(ground_truths)\n",
        "\n",
        "        if self.debug:\n",
        "            print(\"\\n{0}run_ap_calculation{0}\".format('--'*20))\n",
        "            print('true positives and false positives returned from the \"match\" method:'\n",
        "                  '\\ntrue_positives:\\t\\t{}\\nfalse_positives:\\t{}'.format(true_positives.numpy(),\n",
        "                                                                       false_positives.numpy()))\n",
        "            print('\\ntrue positives and false positives after cumulative sum:'\n",
        "                  '\\nself.true_positives:\\t{}\\nself.false_positives:\\t{}'.format(self.true_positives,\n",
        "                                                                                 self.false_positives))\n",
        "\n",
        "            print('\\nprecision calculated using true positive and false positive:\\n'\n",
        "                  'self.precisions:\\t{}'.format(self.precisions))\n",
        "            print('\\nrecall calculated using true positive and false negative:\\n'\n",
        "                  'self.recalls:\\t\\t{}'.format(self.recalls))\n",
        "\n",
        "        # Return VOC mAP value.\n",
        "        return self.get_voc_ap()\n",
        "\n",
        "    # calculate VOC mAP\n",
        "    def get_voc_ap(self):\n",
        "        \"\"\"\n",
        "            Evaluates VOC Mean Average Precision\n",
        "\n",
        "        \"\"\"\n",
        "        # Define average precision tensor.\n",
        "        self.average_precision = tf.Variable(0, dtype=tf.float64)\n",
        "\n",
        "        # Check whether recalls and precisions values were recalculated.\n",
        "        if self.precisions is None or self.recalls is None:\n",
        "            self.average_precision = tf.Variable(np.nan)\n",
        "            return self.average_precision\n",
        "\n",
        "        if self.use_07_metric:\n",
        "\n",
        "            # Iterate over recall levels.\n",
        "            for i, recall_level in enumerate(self.recall_levels):\n",
        "                # Get tensor of boolean values where recalls are greater or equal to recall level.\n",
        "                recalls_check = tf.math.greater_equal(self.recalls, recall_level)\n",
        "\n",
        "                # Check the sum of True values from recalls_check tensor.\n",
        "                if tf.math.reduce_sum(tf.cast(recalls_check, tf.float64)) == 0.:\n",
        "                    val = tf.Variable(0., dtype=tf.float64)\n",
        "                else:\n",
        "                    # Precision needs to be interpolated at different points of recall.\n",
        "                    # Precision at any point of recall will be equal to maximum precision\n",
        "                    # among all precisions correspond to all recalls greater than or equal to the recall point.\n",
        "                    val = tf.math.reduce_max(self.precisions[recalls_check])\n",
        "\n",
        "                self.precision_levels[i].assign(val)\n",
        "\n",
        "                # Update average_precision with value.\n",
        "                self.average_precision = self.average_precision + val\n",
        "\n",
        "            # Get mean average precision.\n",
        "            self.average_precision = self.average_precision / float(self.recall_levels.shape[0])\n",
        "\n",
        "\n",
        "            print(\"\\n{0}get_voc_ap_11_points{0}\".format('--'*21))\n",
        "            print('\\n{} recall points:\\n{}'.format(len(self.recall_levels), self.recall_levels))\n",
        "            print('\\n{}-points interpolated precision:\\n{}'.format(len(self.recall_levels),\n",
        "                                                                   self.precision_levels.numpy()))\n",
        "            print('\\n{}-points average precision:\\t{}'.format(len(self.recall_levels),\n",
        "                                                              self.average_precision))\n",
        "\n",
        "\n",
        "        # Compute AP using all-points interpolation.\n",
        "        else:\n",
        "\n",
        "            mean_recall = tf.concat([[0.], self.recalls, [1.]], axis=-1)\n",
        "            mean_precision = tf.concat([[0.], self.precisions, [0.]], axis=-1)\n",
        "\n",
        "            # Compute the precision envelope.\n",
        "            for i in range(mean_precision.shape[0] - 1, 0, -1):\n",
        "                changed_precision = tf.maximum(mean_precision[i - 1], mean_precision[i])\n",
        "                mean_precision = tf.tensor_scatter_nd_update(mean_precision, [[i-1]], [changed_precision])\n",
        "\n",
        "            # To calculate area under PR curve, look for points\n",
        "            # where X axis (recall) changes value.\n",
        "            idx = tf.squeeze(tf.where(mean_recall[1:] != mean_recall[:-1]), axis=-1)\n",
        "\n",
        "\n",
        "            self.average_precision= tf.math.reduce_sum(\n",
        "                                        tf.multiply((tf.gather(mean_recall,idx+1) - tf.gather(mean_recall,idx)),\n",
        "                                            tf.gather(mean_precision, idx+1)))\n",
        "\n",
        "\n",
        "            self.recall_levels = mean_recall[:-1]\n",
        "            self.precision_levels = mean_precision[:-1]\n",
        "\n",
        "\n",
        "            print(\"\\n{0}get_voc_ap_all_points{0}\".format('--'*21))\n",
        "            print('\\nRecall points:\\n{}'.format(self.recall_levels))\n",
        "            print('\\nAll-points interpolated precision:\\n{}'.format(self.precision_levels.numpy()))\n",
        "            print('\\nAll-points average precision:\\t{}'.format(self.average_precision.numpy()))\n",
        "\n",
        "\n",
        "        return self.average_precision\n",
        "\n",
        "    # Plot precision recall curve.\n",
        "    def precision_recall_curve(self):\n",
        "        \"\"\"\n",
        "            Precision-recall curve visualization for specified class\n",
        "\n",
        "            Parameters:\n",
        "                experiment_name: title of the running experiment\n",
        "        \"\"\"\n",
        "        # Plot the curve.\n",
        "        fig, ax = plt.subplots(figsize=(15,10))\n",
        "        ax.set_ylim([-0.05, 1.05])\n",
        "\n",
        "        if self.use_07_metric:\n",
        "\n",
        "            ax.plot(self.recalls, self.precisions, label='precision-recall')\n",
        "            ax.plot(self.recall_levels.numpy(), self.precision_levels.numpy(), '*',\n",
        "                     label='{}-points interpolation'.format(len(self.recall_levels)))\n",
        "            ax.set_xlabel('recall')\n",
        "            ax.set_ylabel('precision')\n",
        "            ax.legend(loc='best')\n",
        "\n",
        "            plt.show(block=block_plot)\n",
        "\n",
        "        else:\n",
        "            recalls = self.recall_levels.numpy()\n",
        "            interp_prec = self.precision_levels.numpy()\n",
        "\n",
        "            ids = np.where(recalls[1:]!=recalls[:-1])[0]\n",
        "            unique_precs = np.unique(interp_prec[ids+1])[::-1]\n",
        "\n",
        "            recall_st = []\n",
        "            recall_end = []\n",
        "\n",
        "            for un_pr in unique_precs:\n",
        "                id_pr = np.where(np.isclose(interp_prec,un_pr))[0]\n",
        "                recall_st.append(recalls[id_pr][0])\n",
        "                recall_end.append(recalls[id_pr][-1])\n",
        "\n",
        "            ax.plot(self.recalls, self.precisions, 'b', linewidth=3, label='precision-recall')\n",
        "            ax.plot(self.recall_levels.numpy(), self.precision_levels.numpy(), 'r--', linewidth=3,\n",
        "                     label='All-points interpolation')\n",
        "\n",
        "            for i in range(len(unique_precs)):\n",
        "\n",
        "                width   = recall_end[i]-recall_st[i]\n",
        "                height  = unique_precs[i]\n",
        "\n",
        "                label   = 'A{}'.format(i+1)\n",
        "                x_label = recall_st[i] + width/2.5\n",
        "                y_label = height/2\n",
        "\n",
        "                ax.add_patch(\n",
        "                        patches.Rectangle(\n",
        "                            (recall_st[i], 0), width, height,\n",
        "                            fill=False, color='g',linewidth = 2\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                ax.text(x_label, y_label, label, color='g', fontsize=30,\n",
        "                                bbox=dict(facecolor='none', edgecolor='g'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ax.set_xlabel('recall')\n",
        "            ax.set_ylabel('precision')\n",
        "            ax.legend(loc='best')\n",
        "\n",
        "            plt.show(block=block_plot)"
      ],
      "metadata": {
        "id": "QLhV_24-FxvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap_evaluator = AveragePrecisionEvaluator(use_07_metric=True,debug=True)\n",
        "_ = ap_evaluator.run_ap_calculation(detections, ground_truths)\n",
        "ap_evaluator.precision_recall_curve()"
      ],
      "metadata": {
        "id": "pJpZRoJVF43F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All point interpolated precision"
      ],
      "metadata": {
        "id": "YPatazgnGlnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap_evaluator = AveragePrecisionEvaluator(debug=True)\n",
        "ap_evaluator.run_ap_calculation(detections, ground_truths)\n",
        "ap_evaluator.precision_recall_curve()"
      ],
      "metadata": {
        "id": "9xRlyELhGyam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groundTruths =  [\n",
        "                 ['1', tf.Variable([25,  16,  63,  72],  dtype=tf.float32)],\n",
        "                 ['1', tf.Variable([129, 123, 170, 185], dtype=tf.float32)],\n",
        "                 ['2', tf.Variable([123,  11, 166,  66], dtype=tf.float32)],\n",
        "                 ['2', tf.Variable([ 38, 132,  97, 177], dtype=tf.float32)],\n",
        "                 ['3', tf.Variable([ 16,  14,  51,  62], dtype=tf.float32)],\n",
        "                 ['3', tf.Variable([123,  30, 172,  74], dtype=tf.float32)],\n",
        "                 ['3', tf.Variable([ 99, 139, 146, 186], dtype=tf.float32)],\n",
        "                 ['4', tf.Variable([ 53,  42,  93,  94], dtype=tf.float32)],\n",
        "                 ['4', tf.Variable([154,  43, 185,  77], dtype=tf.float32)],\n",
        "                 ['5', tf.Variable([ 59,  31, 103,  82], dtype=tf.float32)],\n",
        "                 ['5', tf.Variable([ 48, 128,  82, 180], dtype=tf.float32)],\n",
        "                 ['6', tf.Variable([ 36,  89,  88, 165], dtype=tf.float32)],\n",
        "                 ['6', tf.Variable([ 62,  58, 106, 125], dtype=tf.float32)],\n",
        "                 ['7', tf.Variable([ 28,  31,  83,  94], dtype=tf.float32)],\n",
        "                 ['7', tf.Variable([ 58,  67, 108, 125], dtype=tf.float32)]\n",
        "                ]\n",
        "\n",
        "detections = [\n",
        "                 ['1', tf.Variable([  5,  67,  36, 115], dtype=tf.float32), tf.Variable(.88)],\n",
        "                 ['1', tf.Variable([119, 111, 159, 178], dtype=tf.float32), tf.Variable(.70)],\n",
        "                 ['1', tf.Variable([124,   9, 173,  76], dtype=tf.float32), tf.Variable(.80)],\n",
        "                 ['2', tf.Variable([ 64, 111, 128, 169], dtype=tf.float32), tf.Variable(.71)],\n",
        "                 ['2', tf.Variable([ 26, 140,  86, 187], dtype=tf.float32), tf.Variable(.54)],\n",
        "                 ['2', tf.Variable([ 19,  18,  62,  53], dtype=tf.float32), tf.Variable(.74)],\n",
        "                 ['3', tf.Variable([109,  15, 186,  54], dtype=tf.float32), tf.Variable(.18)],\n",
        "                 ['3', tf.Variable([ 86,  63, 132, 108], dtype=tf.float32), tf.Variable(.67)],\n",
        "                 ['3', tf.Variable([160,  62, 196, 115], dtype=tf.float32), tf.Variable(.38)],\n",
        "                 ['3', tf.Variable([105, 131, 152, 178], dtype=tf.float32), tf.Variable(.91)],\n",
        "                 ['3', tf.Variable([ 18, 148,  58, 192], dtype=tf.float32), tf.Variable(.44)],\n",
        "                 ['4', tf.Variable([ 83,  28, 111,  54], dtype=tf.float32), tf.Variable(.35)],\n",
        "                 ['4', tf.Variable([ 28,  68,  70, 135], dtype=tf.float32), tf.Variable(.78)],\n",
        "                 ['4', tf.Variable([ 87,  89, 112, 128], dtype=tf.float32), tf.Variable(.45)],\n",
        "                 ['4', tf.Variable([ 10, 155,  70, 181], dtype=tf.float32), tf.Variable(.14)],\n",
        "                 ['5', tf.Variable([ 50,  38,  78,  84], dtype=tf.float32), tf.Variable(.62)],\n",
        "                 ['5', tf.Variable([ 95,  11, 148,  39], dtype=tf.float32), tf.Variable(.44)],\n",
        "                 ['5', tf.Variable([ 29, 131, 101, 160], dtype=tf.float32), tf.Variable(.95)],\n",
        "                 ['5', tf.Variable([ 29, 163, 101, 192], dtype=tf.float32), tf.Variable(.23)],\n",
        "                 ['6', tf.Variable([ 43,  48, 117,  86], dtype=tf.float32), tf.Variable(.45)],\n",
        "                 ['6', tf.Variable([ 17, 155,  46, 190], dtype=tf.float32), tf.Variable(.84)],\n",
        "                 ['6', tf.Variable([ 95, 110, 120, 152], dtype=tf.float32), tf.Variable(.43)],\n",
        "                 ['7', tf.Variable([ 16,  20, 117, 108], dtype=tf.float32), tf.Variable(.48)],\n",
        "                 ['7', tf.Variable([ 33, 116,  70, 165], dtype=tf.float32), tf.Variable(.95)]\n",
        "                ]"
      ],
      "metadata": {
        "id": "A_6N3nOvG7nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap_evaluator = AveragePrecisionEvaluator(intersection_threshold=0.3, debug=True)\n",
        "ap_evaluator.run_ap_calculation(detections,groundTruths)\n",
        "ap_evaluator.precision_recall_curve()"
      ],
      "metadata": {
        "id": "nyoI3BkIG8Cn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}