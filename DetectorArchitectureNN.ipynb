{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq8N_aj3fBGP",
        "outputId": "62b5a42e-139f-4e51-f6d9-beada7e5e138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# For Kaggle training downgrade the keras library\n",
        "!pip install keras==2.15.0 tensorflow==2.15.0 -q\n",
        "\n",
        "# Restart session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# required imports\n",
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XbtO3eoEkChI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, save_name):\n",
        "  file = requests.get(url)\n",
        "  open(save_name, 'wb').write(file.content)\n",
        "  return"
      ],
      "metadata": {
        "id": "AFfa0KtLkDvz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file_pzth=None):\n",
        "    try:\n",
        "        with ZipFile(zip_file_path) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(f\"Extracted {zip_file_path}...\\n\")\n",
        "    except:\n",
        "        print(\"Invalid file\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "AiyNDlcukPmk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('models'):\n",
        "    download_file(\n",
        "                  'https://www.dropbox.com/s/bqedbdn58sw5dl5/detector_nn_architecture.zip?dl=1',\n",
        "                  'detector_nn_architecture.zip'\n",
        "                 )\n",
        "\n",
        "    unzip('detector_nn_architecture.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_EJtFvIkj84",
        "outputId": "87c4f944-db0d-4075-80a0-079ad1ba8611"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QUm0ENKkpPu",
        "outputId": "94333832-96ec-4fce-d9b5-e0572ca59cb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'detector_nn_architecture.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IPCvTObklU5P",
        "outputId": "4be3a8e0-9201-4118-eaef-0ec373308756"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip detector_nn_architecture.zip -d .\n",
        "os.listdir(\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGZ-VPHFlc7M",
        "outputId": "2a369386-9d7d-4dc6-bbe5-a78fcfdba905"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  detector_nn_architecture.zip\n",
            "   creating: ./models/\n",
            "   creating: ./models/resnet18_notop/\n",
            "  inflating: ./models/resnet18_notop/saved_model.pb  \n",
            "  inflating: ./models/resnet18_notop/keras_metadata.pb  \n",
            "   creating: ./models/resnet18_notop/variables/\n",
            "  inflating: ./models/resnet18_notop/variables/variables.index  \n",
            "  inflating: ./models/resnet18_notop/variables/variables.data-00000-of-00001  \n",
            "   creating: ./models/resnet18_notop/assets/\n",
            "   creating: ./test_images/\n",
            "  inflating: ./test_images/FudanPed00002.png  \n",
            "  inflating: ./test_images/FudanPed00001.png  \n",
            "  inflating: ./fpn.py                \n",
            "  inflating: ./detector.py           \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'detector.py',\n",
              " 'test_images',\n",
              " 'detector_nn_architecture.zip',\n",
              " 'models',\n",
              " 'fpn.py',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content')"
      ],
      "metadata": {
        "id": "K6JG3Gh5l7JM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detector Architecture\n",
        "from detector import get_detector"
      ],
      "metadata": {
        "id": "w5E_IjQCkq5t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (300, 300, 3)\n",
        "backbone_name = \"resnet_18\"\n",
        "num_classes = 2\n",
        "fpn_channels = 32\n",
        "num_anchors = 9"
      ],
      "metadata": {
        "id": "XjodGMP4mC_h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = get_detector(\n",
        "    input_shape=input_shape,\n",
        "    backbone_name=\"resnet_18\",\n",
        "    num_classes=num_classes,\n",
        "    fpn_channels=fpn_channels,\n",
        "    num_anchors=num_anchors\n",
        ")\n",
        "\n",
        "tf.keras.utils.plot_model(detector, to_file='detector.png', show_shapes=True, rankdir='TB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "IvtyQ42amE4k",
        "outputId": "335353b8-3f29-4aac-f332-5dfb40f9b7cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=/content/models/resnet18_notop. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/content/models/resnet18_notop, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3246629636.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m detector = get_detector(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbackbone_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resnet_18\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfpn_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpn_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detector.py\u001b[0m in \u001b[0;36mget_detector\u001b[0;34m(input_shape, backbone_name, num_classes, fpn_channels, num_anchors)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Layer Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mfpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fpn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detector.py\u001b[0m in \u001b[0;36mget_backbone\u001b[0;34m(backbone_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackbone_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"resnet_18\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resnet18_notop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbackbone_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"resnet_50\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;34mf\"File format not supported: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;34m\"Keras 3 only supports V3 `.keras` files and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=/content/models/resnet18_notop. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/content/models/resnet18_notop, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from detector import get_backbone\n",
        "\n",
        "input_layer = tf.keras.Input(shape=input_shape)\n",
        "preprocess_modes = {\"resnet_18\": \"torch\", \"resnet_50\": \"caffe\"}\n",
        "model_input = preprocess_input(input_layer, mode=preprocess_modes[backbone_name])\n",
        "backbone = get_backbone(backbone_name=backbone_name)\n",
        "layer_3_out, layer_4_out, layer_5_out = backbone(model_input)"
      ],
      "metadata": {
        "id": "LKB15Mj8msh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpn import Lateral_Connection\n",
        "\n",
        "def get_fpn(backbone_out, channels_out):\n",
        "\n",
        "    # FPN inputs\n",
        "    in_backbone_out_3, in_backbone_out_4, in_backbone_out_5 = backbone_out\n",
        "\n",
        "    # 1x1 conv output\n",
        "    p5_out = tf.keras.layers.Conv2D(channels_out, 1, 1, \"same\", name=\"p5_out_1x1\")(in_backbone_out_5)\n",
        "\n",
        "    # lateral connection\n",
        "    p4_out = Lateral_Connection(channels_out, name=\"lat_con_p4_out\")((p5_out, in_backbone_out_4))\n",
        "    p3_out = Lateral_Connection(channels_out, name=\"lat_con_p3_out\")((p4_out, in_backbone_out_3))\n",
        "\n",
        "    # 3x3 conv output\n",
        "    p3_out = tf.keras.layers.Conv2D(channels_out, 3, 1, \"same\", name=\"p3_out_3x3\")(p3_out)\n",
        "    p4_out = tf.keras.layers.Conv2D(channels_out, 3, 1, \"same\", name=\"p4_out_3x3\")(p4_out)\n",
        "    p5_out = tf.keras.layers.Conv2D(channels_out, 3, 1, \"same\", name=\"p5_out_3x3\")(p5_out)\n",
        "\n",
        "    fpn = tf.keras.Model(inputs=[in_backbone_out_3, in_backbone_out_4, in_backbone_out_5],\n",
        "                         outputs=[p3_out, p4_out, p5_out], name=\"FPN\")\n",
        "    return fpn"
      ],
      "metadata": {
        "id": "Vdy1aNGYobdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the FPN model\n",
        "fpn_model = get_fpn(backbone_out=(layer_3_out, layer_4_out, layer_5_out), channels_out=32)\n",
        "# Plot the FPN model\n",
        "tf.keras.utils.plot_model(fpn_model, to_file='fpn.png', show_shapes=True, rankdir='TB')"
      ],
      "metadata": {
        "id": "r8tMQF73odOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "\n",
        "import cv2\n",
        "\n",
        "img1 = cv2.imread(\"./test_images/FudanPed00001.png\")\n",
        "img2 = cv2.imread(\"./test_images/FudanPed00002.png\")\n",
        "\n",
        "img1 = tf.convert_to_tensor(cv2.resize(img1, (300, 300)) / 255., dtype = tf.float32)\n",
        "img2 = tf.convert_to_tensor(cv2.resize(img2, (300, 300)) / 255., dtype = tf.float32)\n",
        "\n",
        "images = tf.convert_to_tensor([img1, img2])\n",
        "\n",
        "# Already initialized the detector model. Now let's predict\n",
        "preds = detector.predict(images)\n",
        "\n",
        "print('location_pred size: {}'.format(preds[0].shape))\n",
        "print('class_pred size: {}'.format(preds[1].shape))"
      ],
      "metadata": {
        "id": "_7HzWJS2o1tf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}