{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExKrBpQQXeuo"
      },
      "outputs": [],
      "source": [
        "!apt install cuda-11-8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_PATH=/usr/local/cuda-11.8/"
      ],
      "metadata": {
        "id": "-Usv9WepXyJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "vviy_QdAXzqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "WHgGUuRBX3fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need to update OpenCV if you are using Colab.\n",
        "# Uncomment this line if you are using Colab.\n",
        "!pip install opencv-python --upgrade"
      ],
      "metadata": {
        "id": "gMSlnt22X6q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "pl5ZxAYGX8f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not 'models' in os.listdir():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "tDa3jwrcYAtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyCocoTools\n",
        "!pip install pycocotools"
      ],
      "metadata": {
        "id": "I7Eyq6HLYCS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The `%%bash` magic command inside a notebook lets you run a cell run like a shell interface\n",
        "# Note: the `bash` command works only on Colab.\n",
        "%%bash\n",
        "\n",
        "# Change the directory to models/research\n",
        "cd models/research/\n",
        "\n",
        "# Compile the API's Protobuf files\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Copy the required Setup file\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "\n",
        "# Install the API using the setup.py file\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "I_JNUShsYD3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.13.0"
      ],
      "metadata": {
        "id": "cAqiK1l4YFi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the API if everything was installed correctly\n",
        "!python models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "YyxHe4MBYHxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import urllib\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "OyzFFsd2YJq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, save_name):\n",
        "    url = url\n",
        "    file = requests.get(url)\n",
        "\n",
        "    open(save_name, 'wb').write(file.content)"
      ],
      "metadata": {
        "id": "LArpViwkYMNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")"
      ],
      "metadata": {
        "id": "HsBoRSNJYNot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the PASCAL VOC subset data.\n",
        "download_file(\n",
        "                  'https://www.dropbox.com/s/415tmokwg5xkw99/pascal_voc_subset_data.zip?dl=1',\n",
        "                  'pascal_voc_subset_data.zip'\n",
        "                 )"
      ],
      "metadata": {
        "id": "AJpi-zYLYOxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip(zip_file='pascal_voc_subset_data.zip')"
      ],
      "metadata": {
        "id": "62iTcUQOYQRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "LRubCgDhYR9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('tfod_utils'):\n",
        "    download_file(\n",
        "                  'https://www.dropbox.com/sh/i5uds5hgzc0phik/AADHAlWQk7VmTSFtoWj9pBZJa?dl=1',\n",
        "                  'tfod_utils_pascal_voc_subset.zip'\n",
        "                 )\n",
        "    unzip(zip_file='tfod_utils_pascal_voc_subset.zip')"
      ],
      "metadata": {
        "id": "TFUXfE2tYdAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate LabelMap File\n",
        "# Create Label Map of the Dataset\n",
        "pbtxt = '''\n",
        "item {\n",
        "    name: 'car',\n",
        "    id: 1,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'dog',\n",
        "    id: 2,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'person',\n",
        "    id: 3,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'tvmonitor',\n",
        "    id: 4,\n",
        "}\n",
        "'''\n",
        "\n",
        "# Save this labelmap to disk\n",
        "with open(\"labelmap.pbtxt\", \"w\") as text_file:\n",
        "    text_file.write(pbtxt)"
      ],
      "metadata": {
        "id": "7_zQhiqRYdmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate TF Records\n",
        "# create tf_record for train data\n",
        "!python ./tfod_utils/xml_to_csv.py -x train -c train_data.csv\n",
        "!python ./tfod_utils/generate_tfrecord.py --csv_input=train_data.csv --output_path=train_data.tfrecord --image_dir=train --labelmap_path=labelmap.pbtxt"
      ],
      "metadata": {
        "id": "0e3ZJY-JYhiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create tf_record for val data\n",
        "!python ./tfod_utils/xml_to_csv.py -x val -c val_data.csv\n",
        "!python ./tfod_utils/generate_tfrecord.py --csv_input=val_data.csv --output_path=val_data.tfrecord --image_dir=val --labelmap_path=labelmap.pbtxt"
      ],
      "metadata": {
        "id": "2BGE9wTtYkyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_dict = {'car': (255,255,0), 'dog': (0,255,0), 'person': (255,125,125), 'tvmonitor': (0,255,255)}"
      ],
      "metadata": {
        "id": "2W8vAGv5Ym-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to parse the TF Record so we can visualize it\n",
        "def parse_record(data_record):\n",
        "    \"\"\"\n",
        "    Parse the data record from a tfrecord file, typically pulled from an iterator,\n",
        "    in this case a one_shot_iterator created from the dataset.\n",
        "\n",
        "    Args:\n",
        "    data_record:  Path for the TF Record we want to parse\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a feature dictionary containing the information we want from the\n",
        "    # The TF Record file after it is parsed\n",
        "    feature = {'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "                  'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "                  'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/filename': tf.io.FixedLenFeature([], tf.string)\n",
        "                  }\n",
        "\n",
        "    # Parse each entry in the TF Record\n",
        "    parsed_example = tf.io.parse_single_example(data_record, feature)\n",
        "\n",
        "    # Get File name from parsed entry\n",
        "    fname = parsed_example['image/filename'].numpy()\n",
        "\n",
        "    # Get the encoded from parsed entry\n",
        "    encoded_image = parsed_example['image/encoded']\n",
        "\n",
        "    # Decode the image into an array\n",
        "    image_np = tf.image.decode_image(encoded_image, channels=3).numpy()\n",
        "\n",
        "    # Convert Sparse Tensor to Dense tensor so we get the complete information\n",
        "    # Regarding each of the features\n",
        "    labels =  tf.sparse.to_dense(parsed_example['image/object/class/label'],\n",
        "                                    default_value=0).numpy()\n",
        "    x1norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/xmin'],\n",
        "                                    default_value=0).numpy()\n",
        "    x2norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/xmax'],\n",
        "                                    default_value=0).numpy()\n",
        "    y1norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/ymin'],\n",
        "                                    default_value=0).numpy()\n",
        "    y2norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/ymax'],\n",
        "                                    default_value=0).numpy()\n",
        "\n",
        "    # Number of bounding boxes in an image\n",
        "    num_bboxes = len(labels)\n",
        "\n",
        "    # Get height and width of image\n",
        "    height, width = image_np[:, :, 1].shape\n",
        "\n",
        "    # Return the Parsed TF Recrods Image attributes\n",
        "    return fname, image_np, labels, x1norm, x2norm, y1norm, y2norm, num_bboxes, height, width"
      ],
      "metadata": {
        "id": "6aELjaVkYs7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to Visualize the TF Records File\n",
        "def view_records(file_path, class_labels):\n",
        "    \"\"\"\n",
        "    Peek at the data using OpenCV and TensorFlow tools.\n",
        "\n",
        "    Args:\n",
        "      file_path: Path to tfrecord file (usually has 'record' extension)\n",
        "      class_labels: Dictionary of labels with name:number pairs (start with 1)\n",
        "      verbose (default 1): Display text output if 1, display nothing except\n",
        "      images otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the TF Record Dataset\n",
        "    dataset = tf.data.TFRecordDataset([file_path])\n",
        "\n",
        "    # Convert the dataset into an iterator so we can loop through images\n",
        "    record_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
        "\n",
        "    # Find the number of images and their labels in our dataset\n",
        "    num_records = dataset.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
        "\n",
        "    # Loop over the 10 images to visualize the dataset\n",
        "    for im_ind in range(10):\n",
        "\n",
        "        # Parse each entry in the TF Record\n",
        "        parsed_example = parse_record(record_iterator.get_next())\n",
        "\n",
        "        # Get attributes about each image after being parsed\n",
        "        fname, image_np, labels, x1norm, x2norm, y1norm, y2norm, num_bboxes, height, width = parse_record(record_iterator.get_next())\n",
        "\n",
        "        # Create a copy of the image we read so original image stays same\n",
        "        image_copy = image_np.copy()\n",
        "\n",
        "        # Convert the image to RGB\n",
        "        image_rgb = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Check to see if an image has bounding boxes\n",
        "        if num_bboxes > 0:\n",
        "\n",
        "            # Multiply the width and height bounding box values to rescale them\n",
        "            # Back to their original value\n",
        "            x1 = np.int64(x1norm*width)\n",
        "            x2 = np.int64(x2norm*width)\n",
        "            y1 = np.int64(y1norm*height)\n",
        "            y2 = np.int64(y2norm*height)\n",
        "\n",
        "            # Loop over the number of the bounding boxes so each one can be drawn\n",
        "            for bbox_ind in range(num_bboxes):\n",
        "\n",
        "                # Create a tuple of the bbox values\n",
        "                bbox = (x1[bbox_ind], y1[bbox_ind], x2[bbox_ind], y2[bbox_ind])\n",
        "\n",
        "                # Get the Label Name of each of the bounding box\n",
        "                label_name = list(class_labels.keys())[list(class_labels.values()).index(labels[bbox_ind])]\n",
        "\n",
        "                color = color_dict[label_name]\n",
        "\n",
        "                # Draw the bounding box\n",
        "                cv2.rectangle(image_rgb, (bbox[0], bbox[1]), (bbox[2], bbox[3]),\n",
        "                                color, 2)\n",
        "\n",
        "                # Get text width and height\n",
        "                ((text_width, text_height), _) = cv2.getTextSize(label_name, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)\n",
        "\n",
        "                cv2.rectangle(image_rgb, (bbox[0], bbox[1] - int(0.9 * text_height)), (bbox[0] + int(0.4*text_width), bbox[1]), color, thickness=-1)\n",
        "\n",
        "                # Write the detected class name for each bounding box\n",
        "                cv2.putText(image_rgb, label_name,\n",
        "                            (bbox[0],bbox[1] - int(0.3 * text_height)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "\n",
        "\n",
        "        # Show the image\n",
        "        plt.figure(figsize=(10,10));\n",
        "        plt.imshow(image_rgb[...,::-1]);\n",
        "        plt.axis('off');\n",
        "        plt.title(f\"Height/Width: {height, width}, Num bboxes: {num_bboxes}\")"
      ],
      "metadata": {
        "id": "9t4E8nk5YvpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a class_labels dictionary same as the label map\n",
        "class_labels =  {\"car\" : 1, \"dog\": 2, \"person\": 3, \"tvmonitor\": 4}\n",
        "\n",
        "\n",
        "# We're Visualizing the train TF Record, you can also visualize the test record file.\n",
        "data_path = \"val_data.tfrecord\"\n",
        "\n",
        "# Call the view_records\n",
        "view_records(data_path, class_labels)"
      ],
      "metadata": {
        "id": "zdAB702LYxsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Train Faster RCNN (with ResNet101 backbone)"
      ],
      "metadata": {
        "id": "XuKwIrcZY0vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Download any model from Model Zoo from their URL\n",
        "def download_model(model_name, url):\n",
        "\n",
        "    # Initialize the Downloader object of urllib\n",
        "    opener  = urllib.request.URLopener()\n",
        "    opener.retrieve(url, model_name+'.tar.gz')\n",
        "\n",
        "    # Extract the Model\n",
        "    tar = tarfile.open(model_name + '.tar.gz')\n",
        "    tar.extractall(model_name)\n",
        "    tar.close"
      ],
      "metadata": {
        "id": "Ra0fN4p4Y6p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define URL and name of the Model\n",
        "model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz'\n",
        "model_directory = 'Faster_RCNN_Resnet_101'\n",
        "\n",
        "model_name = model_url.split('/')[-1].split('.')[0] # faster_rcnn_resnet101_v1_640x640_coco17_tpu-8\n",
        "\n",
        "# Download FasterRCNN from the Model Zoo\n",
        "download_model(model_directory, model_url)"
      ],
      "metadata": {
        "id": "0REqFPh5Y9GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths of Train and Test TF Record Files\n",
        "train_record_path = 'train_data.tfrecord'\n",
        "test_record_path = 'val_data.tfrecord'\n",
        "\n",
        "# Path of Label Map of the Dataset\n",
        "labelmap_path = 'labelmap.pbtxt'\n",
        "\n",
        "# Checkpoint File of the Pre-Trained model so we can use what the model has learned\n",
        "fine_tune_checkpoint_path = os.path.join(model_directory, model_name, 'checkpoint', 'ckpt-0')\n",
        "\n",
        "# Type of model of how we will use it\n",
        "fine_tune_checkpoint_type = 'detection'\n",
        "\n",
        "# Set Batch Size\n",
        "batch_size = 5\n",
        "\n",
        "# Set this to True only if using TPU for training\n",
        "bfloat = False\n",
        "\n",
        "# Number of Training Steps\n",
        "num_steps = 20000\n",
        "# Uncomment the below line if you want first to verify the training pipeline.\n",
        "# num_steps = 1000\n",
        "\n",
        "# Initial LR\n",
        "initial_lr = 0.0003\n",
        "\n",
        "# Path of the pipeline file we downloaded\n",
        "base_config_path = os.path.join(model_directory, model_name, 'pipeline.config')\n",
        "\n",
        "# Number of classes from Dataset\n",
        "num_classes = 4"
      ],
      "metadata": {
        "id": "kx_VgxuEY_DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the API's config_util file to read the config file and edit it\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "4tBCjAAzZFs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_fine_tune_checkpoint_path(train_config, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    train_config: train_pb2.TrainConfig object.\n",
        "    checkpoint_path: path to pre-trained modelâ€™s checkpoint.\n",
        "    \"\"\"\n",
        "\n",
        "    train_config.fine_tune_checkpoint = checkpoint_path\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "8XqUcZ7sZHMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_fine_tune_checkpoint_type(train_config, fine_tune_checkpoint_type):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    train_config: train_pb2.TrainConfig object.\n",
        "    fine_tune_checkpoint_type: determines the type of weights that are restored from\n",
        "                               from the pre-trained fine_tune_checkpoint.\n",
        "                               Can be either of: \"classification\", \"detection\" or \"full\".\n",
        "    \"\"\"\n",
        "\n",
        "    train_config.fine_tune_checkpoint_type = fine_tune_checkpoint_type\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "Q5rWmu10ZItx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the config file in the form a dictionary\n",
        "configs = config_util.get_configs_from_pipeline_file(base_config_path)\n",
        "\n",
        "# Update the Training TF Record file path\n",
        "config_util.update_input_reader_config(configs,\n",
        "                                       'train_input_config',\n",
        "                                       'tf_record_input_reader',\n",
        "                                       'input_path',\n",
        "                                       train_record_path,\n",
        "                                      )\n",
        "\n",
        "# Update the Testing TF Record file path\n",
        "config_util.update_input_reader_config(configs,\n",
        "                                       'eval_input_config',\n",
        "                                       'tf_record_input_reader',\n",
        "                                       'input_path',\n",
        "                                       test_record_path,\n",
        "                                      )\n",
        "\n",
        "# Update fine tune checkpoint path\n",
        "update_fine_tune_checkpoint_path(configs['train_config'], fine_tune_checkpoint_path)\n",
        "\n",
        "# Update fine tune checkpoint type\n",
        "update_fine_tune_checkpoint_type(configs['train_config'], fine_tune_checkpoint_type)\n",
        "\n",
        "# Update batch size\n",
        "config_util._update_batch_size(configs, batch_size)\n",
        "\n",
        "# Update Number of Steps\n",
        "config_util._update_train_steps(configs, num_steps)\n",
        "\n",
        "# Update Number of Classes\n",
        "config_util._update_num_classes(configs['model'], num_classes)\n",
        "\n",
        "# Update Label Map path\n",
        "config_util._update_label_map_path(configs, labelmap_path)\n",
        "\n",
        "# Update bfloat16 value\n",
        "config_util._update_use_bfloat16(configs, bfloat)\n",
        "\n",
        "# Update Initial LR\n",
        "config_util._update_initial_learning_rate(configs, initial_lr)\n",
        "\n",
        "# Create a pipeline file instance from the edited configuration instance\n",
        "configs_file = config_util.create_pipeline_proto_from_configs(configs)\n",
        "\n",
        "# Save the pipeline into a directory\n",
        "config_util.save_pipeline_config(configs_file, './')"
      ],
      "metadata": {
        "id": "ax8dyFHZZKm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the Model's weights will be stored\n",
        "# along with training logs during training.\n",
        "model_dir = 'training_of_model'"
      ],
      "metadata": {
        "id": "Hnd0fwimZPAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This loads tensorboad in the notebook\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Magic command to launch tensorboard\n",
        "%tensorboard --logdir {model_dir}"
      ],
      "metadata": {
        "id": "oi2d7OOXZQZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "# Path of the new edited Pipeline Configuration File we will use\n",
        "pipeline_config_path = 'pipeline.config'"
      ],
      "metadata": {
        "id": "57xT8fJuZR5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the TFOD API Script to Initiate Training\n",
        "!python ./models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path={pipeline_config_path} \\\n",
        "  --model_dir={model_dir} \\\n",
        "  --alsologtostderr"
      ],
      "metadata": {
        "id": "pg68jJJ7ZWsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./models/research/object_detection/model_main_tf2.py \\\n",
        "  --model_dir {model_dir} \\\n",
        "  --pipeline_config_path {pipeline_config_path} \\\n",
        "  --checkpoint_dir {model_dir}"
      ],
      "metadata": {
        "id": "QijNc2BmZYXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKl-jk4LZeEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}