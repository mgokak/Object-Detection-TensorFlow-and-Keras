{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyATpEmrSo9e"
      },
      "outputs": [],
      "source": [
        "# You need to update OpenCV if you are using Colab.\n",
        "# Uncomment this line if you are using Colab.\n",
        "!pip install opencv-python --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not 'models' in os.listdir():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "j6xsEPSRS6dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The `%%bash` magic command inside a notebook lets you run a cell run like a shell interface\n",
        "# Note: the `bash` command works only on Colab.\n",
        "%%bash\n",
        "\n",
        "# Change the directory to models/research\n",
        "cd models/research/\n",
        "\n",
        "# Compile the API's Protobuf files\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Copy the required Setup file\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "\n",
        "# Install the API using the setup.py file\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "8_Rck9rIS8tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix:\n",
        "# - TypeError: Descriptors cannot be created directly,\n",
        "\n",
        "!pip install protobuf==3.20.0"
      ],
      "metadata": {
        "id": "FpEhbbHcS-0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart Session\n",
        "\n",
        "import os\n",
        "# TensorFlow + Keras 2 backwards compatibility\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "HZRvlkymTBD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import urllib\n",
        "import requests\n",
        "\n",
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "N21M39dPTEAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, save_name):\n",
        "  file=requests.get(url)\n",
        "\n",
        "  open(save_name, 'wb').write(file.content)"
      ],
      "metadata": {
        "id": "nPuoMehPTINW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")"
      ],
      "metadata": {
        "id": "yAoalRqcTRSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the PASCAL VOC subset data.\n",
        "download_file(\n",
        "                  'https://www.dropbox.com/s/415tmokwg5xkw99/pascal_voc_subset_data.zip?dl=1',\n",
        "                  'pascal_voc_subset_data.zip'\n",
        "                 )"
      ],
      "metadata": {
        "id": "OuJntqO6TRr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip(zip_file='pascal_voc_subset_data.zip')"
      ],
      "metadata": {
        "id": "MjZCv5mPTTZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('tfod_utils'):\n",
        "    download_file(\n",
        "                  'https://www.dropbox.com/sh/i5uds5hgzc0phik/AADHAlWQk7VmTSFtoWj9pBZJa?dl=1',\n",
        "                  'tfod_utils_pascal_voc_subset.zip'\n",
        "                 )\n",
        "    unzip(zip_file='tfod_utils_pascal_voc_subset.zip')"
      ],
      "metadata": {
        "id": "VGIE1Z4qTVMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a LabelMap File"
      ],
      "metadata": {
        "id": "vuuHVunNTXYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Label Map of the Dataset\n",
        "pbtxt = '''\n",
        "item {\n",
        "    name: 'car',\n",
        "    id: 1,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'dog',\n",
        "    id: 2,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'person',\n",
        "    id: 3,\n",
        "}\n",
        "\n",
        "item {\n",
        "    name: 'tvmonitor',\n",
        "    id: 4,\n",
        "}\n",
        "'''\n",
        "\n",
        "# Save this labelmap to disk\n",
        "with open(\"labelmap.pbtxt\", \"w\") as text_file:\n",
        "    text_file.write(pbtxt)"
      ],
      "metadata": {
        "id": "jufgHIn0Taxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate TF Records"
      ],
      "metadata": {
        "id": "MYjfd2CiTdKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a csv file for the validation data.\n",
        "!python ./tfod_utils/xml_to_csv.py -x val -c val_data.csv"
      ],
      "metadata": {
        "id": "CfZxH541Tfjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tf_record for val data.\n",
        "!python ./tfod_utils/generate_tfrecord.py --csv_input=val_data.csv --output_path=val_data.tfrecord --image_dir=val --labelmap_path=labelmap.pbtxt"
      ],
      "metadata": {
        "id": "vbefilPLTh1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data from TF Records"
      ],
      "metadata": {
        "id": "7FLUiUXDTmHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_dict = {'car': (255,255,0), 'dog': (0,255,0), 'person': (255,125,125), 'tvmonitor': (0,255,255)}"
      ],
      "metadata": {
        "id": "KaWL4yNrTqjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to parse the TF Record so we can visualize it.\n",
        "def parse_record(data_record):\n",
        "    \"\"\"\n",
        "    Parse the data record from a tfrecord file, typically pulled from an iterator,\n",
        "    in this case a one_shot_iterator created from the dataset.\n",
        "\n",
        "    Args:\n",
        "    data_record:  Path for the TF Record we want to parse\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a feature dictionary containing the information we want from the\n",
        "    # the TF Record file after it is parsed.\n",
        "    feature = {'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "                  'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "                  'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "                  'image/filename': tf.io.FixedLenFeature([], tf.string)\n",
        "                  }\n",
        "\n",
        "    # Parse each entry in the TF Record.\n",
        "    parsed_example = tf.io.parse_single_example(data_record, feature)\n",
        "\n",
        "    # Get File name from parsed entry.\n",
        "    fname = parsed_example['image/filename'].numpy()\n",
        "\n",
        "    # Get the encoded from parsed entry.\n",
        "    encoded_image = parsed_example['image/encoded']\n",
        "\n",
        "    # Decode the image into an array.\n",
        "    image_np = tf.image.decode_image(encoded_image, channels=3).numpy()\n",
        "\n",
        "    # Convert Sparse Tensor to Dense tensor so we get the complete information\n",
        "    # regarding each of the features.\n",
        "    labels =  tf.sparse.to_dense(parsed_example['image/object/class/label'],\n",
        "                                    default_value=0).numpy()\n",
        "    x1norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/xmin'],\n",
        "                                    default_value=0).numpy()\n",
        "    x2norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/xmax'],\n",
        "                                    default_value=0).numpy()\n",
        "    y1norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/ymin'],\n",
        "                                    default_value=0).numpy()\n",
        "    y2norm =  tf.sparse.to_dense(parsed_example['image/object/bbox/ymax'],\n",
        "                                    default_value=0).numpy()\n",
        "\n",
        "    # Number of bounding boxes in an image.\n",
        "    num_bboxes = len(labels)\n",
        "\n",
        "    # Get height and width of image.\n",
        "    height, width = image_np[:, :, 1].shape\n",
        "\n",
        "    # Return the Parsed TF Recrods Image attributes.\n",
        "    return fname, image_np, labels, x1norm, x2norm, y1norm, y2norm, num_bboxes, height, width"
      ],
      "metadata": {
        "id": "vy3PD6UpTrEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to Visualize the TF Records File\n",
        "def view_records(file_path, class_labels):\n",
        "    \"\"\"\n",
        "    Peek at the data using OpenCV and TensorFlow tools.\n",
        "\n",
        "    Args:\n",
        "      file_path: Path to tfrecord file (usually has 'record' extension)\n",
        "      class_labels: Dictionary of labels with name:number pairs (start with 1)\n",
        "      verbose (default 1): Display text output if 1, display nothing except\n",
        "      images otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the TF Record Dataset\n",
        "    dataset = tf.data.TFRecordDataset([file_path])\n",
        "\n",
        "    # Convert the dataset into an iterator so we can loop through images\n",
        "    record_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
        "\n",
        "    # Find the number of images and their labels in our dataset\n",
        "    num_records = dataset.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
        "\n",
        "    # Loop over the 10 images to visualize the dataset\n",
        "    for im_ind in range(10):\n",
        "\n",
        "        # Parse each entry in the TF Record\n",
        "        parsed_example = parse_record(record_iterator.get_next())\n",
        "\n",
        "        # Get attributes about each image after being parsed\n",
        "        fname, image_np, labels, x1norm, x2norm, y1norm, y2norm, num_bboxes, height, width = parse_record(record_iterator.get_next())\n",
        "\n",
        "        # Create a copy of the image we read so original image stays same\n",
        "        image_copy = image_np.copy()\n",
        "\n",
        "        # Convert the image to RGB\n",
        "        image_rgb = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Check to see if an image has bounding boxes\n",
        "        if num_bboxes > 0:\n",
        "\n",
        "            # Multiply the width and height bounding box values to rescale them\n",
        "            # Back to their original value\n",
        "            x1 = np.int64(x1norm*width)\n",
        "            x2 = np.int64(x2norm*width)\n",
        "            y1 = np.int64(y1norm*height)\n",
        "            y2 = np.int64(y2norm*height)\n",
        "\n",
        "            # Loop over the number of the bounding boxes so each one can be drawn\n",
        "            for bbox_ind in range(num_bboxes):\n",
        "\n",
        "                # Create a tuple of the bbox values\n",
        "                bbox = (x1[bbox_ind], y1[bbox_ind], x2[bbox_ind], y2[bbox_ind])\n",
        "\n",
        "                # Get the Label Name of each of the bounding box\n",
        "                label_name = list(class_labels.keys())[list(class_labels.values()).index(labels[bbox_ind])]\n",
        "\n",
        "                color = color_dict[label_name]\n",
        "\n",
        "                # Draw the bounding box\n",
        "                cv2.rectangle(image_rgb, (bbox[0], bbox[1]), (bbox[2], bbox[3]),\n",
        "                                color, 2)\n",
        "\n",
        "                # Get text width and height\n",
        "                ((text_width, text_height), _) = cv2.getTextSize(label_name, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)\n",
        "\n",
        "                cv2.rectangle(image_rgb, (bbox[0], bbox[1] - int(0.9 * text_height)), (bbox[0] + int(0.4*text_width), bbox[1]), color, thickness=-1)\n",
        "\n",
        "                # Write the detected class name for each bounding box\n",
        "                cv2.putText(image_rgb, label_name,\n",
        "                            (bbox[0],bbox[1] - int(0.3 * text_height)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "\n",
        "\n",
        "        # Show the image\n",
        "        plt.figure(figsize=(10,10));\n",
        "        plt.imshow(image_rgb[...,::-1]);\n",
        "        plt.axis('off');\n",
        "        plt.title(f\"Height/Width: {height, width}, Num bboxes: {num_bboxes}\")"
      ],
      "metadata": {
        "id": "9upSWfOiT6NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPG7mftqT9H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qVEpdICT_sv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}