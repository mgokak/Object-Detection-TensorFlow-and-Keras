{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpeYZZzJjlaU",
        "outputId": "f9cb22ce-5296-466d-cb95-b05aa44bf2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4395, done.\u001b[K\n",
            "remote: Counting objects: 100% (4395/4395), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3206/3206), done.\u001b[K\n",
            "remote: Total 4395 (delta 1189), reused 3087 (delta 1115), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4395/4395), 70.05 MiB | 24.10 MiB/s, done.\n",
            "Resolving deltas: 100% (1189/1189), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone git repo\n",
        "import os\n",
        "if not 'models' in os.listdir():\n",
        "    !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyCocoTools.\n",
        "!pip install pycocotools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uju0AmMALw_y",
        "outputId": "a5060f82-ecb8-4474-c069-e441adfceb55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Tensoflow object detection\n",
        "\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/photos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPlnEChtLyR_",
        "outputId": "870cf657-ca08-4e77-e81c-3e454cdc6983"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Collecting contextlib2 (from object_detection==0.1)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.19.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.4/55.4 kB 4.2 MB/s eta 0:00:00\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2.0.2)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.187.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.12.0.88)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 3.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.2)\n",
            "Collecting ai-edge-litert>=1.0.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading ai_edge_litert-2.0.3-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 6.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (43.0.3)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.11.4)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 2.6 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting httplib2<0.23.0,>=0.8 (from apache-beam->object_detection==0.1)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.25.1)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (25.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<7.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (5.29.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.32.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.15.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.25.0)\n",
            "Collecting beartype<0.22.0,>=0.21.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (1.4.9)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (4.60.1)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.37.1 (from tensorflow_io->object_detection==0.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting backports.strenum (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.9.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.11)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: PyJWT>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (2.10.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.4-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "INFO: pip is still looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "Collecting tensorflow-hub>=0.6.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tensorflow_hub-0.16.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.10.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.9.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading tensorflow_hub-0.6.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes (from keras->object_detection==0.1)\n",
            "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting h5py (from keras->object_detection==0.1)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.15.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting opencv-python>=4.1.0.25 (from lvis->object_detection==0.1)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.23)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (6.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.3)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 9.5 MB/s eta 0:00:00\n",
            "Downloading tf_models_official-2.19.1-py2.py3-none-any.whl (2.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 49.9 MB/s eta 0:00:00\n",
            "Downloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.2/17.2 MB 111.8 MB/s eta 0:00:00\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 MB 17.3 MB/s eta 0:00:00\n",
            "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 119.9 MB/s eta 0:00:00\n",
            "Downloading ai_edge_litert-2.0.3-cp312-cp312-manylinux_2_27_x86_64.whl (91.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.2/91.2 MB 9.1 MB/s eta 0:00:00\n",
            "Downloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 57.1 MB/s eta 0:00:00\n",
            "Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 105.6 MB/s eta 0:00:00\n",
            "Downloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 114.9 MB/s eta 0:00:00\n",
            "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 8.2 MB/s eta 0:00:00\n",
            "Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.3/46.3 kB 3.5 MB/s eta 0:00:00\n",
            "Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.0/63.0 MB 11.9 MB/s eta 0:00:00\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 20.8 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.0/18.0 MB 76.2 MB/s eta 0:00:00\n",
            "Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 60.7 MB/s eta 0:00:00\n",
            "Downloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.8/272.8 kB 21.7 MB/s eta 0:00:00\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.0/50.0 MB 14.2 MB/s eta 0:00:00\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 26.1 MB/s eta 0:00:00\n",
            "Downloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Building wheels for collected packages: object_detection, avro-python3, crcmod, hdfs, seqeval, docopt\n",
            "  Building wheel for object_detection (setup.py): started\n",
            "  Building wheel for object_detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1609953 sha256=7faaedd1fde43f1444f1b2f8d1dc137ed0cf8b878c9b88c37e53a0f9c1aad542\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l0wacbxg/wheels/93/ad/c5/62cdd10f6d842d66f3d05020591434c5aefd0cdea6bcd6f0ff\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=6ea14ad713e41e510584a7ddba647576e80ecd38d621c0f3d892baad89ebe403\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/82/f4/b7126d86d6a404dd59a822fad5f169000deee5f61f7c88580c\n",
            "  Building wheel for crcmod (setup.py): started\n",
            "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp312-cp312-linux_x86_64.whl size=31833 sha256=4c5d0387b649fc57ecacb715f0d51245f6edea58a90b029630ab65badf4eceec\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/08/0b/caa8b1380122cbfe6a03eaccbec0f63c67e619af4e30ca5e2a\n",
            "  Building wheel for hdfs (setup.py): started\n",
            "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=9b02c03ec47cd64bcdf0ca42dbb3ba8240bf296c7482b9aa3c1c704234e612c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ae/d9/536505928dd3a458b206013b02625df8f12d22fa154f2bfd65\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=1749bfda940a69b8c55ff93d7c87635ed3262770e2da91b8e451a8e7206674cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8006fbb0b3c64fc5f683e3ddd58d513038ddd16df7278e36335993c7113c0e37\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built object_detection avro-python3 crcmod hdfs seqeval docopt\n",
            "Installing collected packages: docopt, crcmod, tensorflow-io-gcs-filesystem, redis, pyparsing, pyarrow-hotfix, portalocker, objsize, numpy, jsonpickle, grpcio, fasteners, fastavro, dnspython, contextlib2, colorama, beartype, backports.strenum, avro-python3, tensorflow_io, sacrebleu, pymongo, pydot, opencv-python-headless, opencv-python, httplib2, hdfs, ai-edge-litert, tensorflow-model-optimization, seqeval, lvis, apache-beam, tf-models-official, object_detection\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.1.1\n",
            "    Uninstalling jsonpickle-4.1.1:\n",
            "      Successfully uninstalled jsonpickle-4.1.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: beartype\n",
            "    Found existing installation: beartype 0.22.6\n",
            "    Uninstalling beartype-0.22.6:\n",
            "      Successfully uninstalled beartype-0.22.6\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 4.0.1\n",
            "    Uninstalling pydot-4.0.1:\n",
            "      Successfully uninstalled pydot-4.0.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.31.0\n",
            "    Uninstalling httplib2-0.31.0:\n",
            "      Successfully uninstalled httplib2-0.31.0\n",
            "Successfully installed ai-edge-litert-2.0.3 apache-beam-2.69.0 avro-python3-1.10.2 backports.strenum-1.2.8 beartype-0.21.0 colorama-0.4.6 contextlib2-21.6.0 crcmod-1.7 dnspython-2.8.0 docopt-0.6.2 fastavro-1.12.1 fasteners-0.20 grpcio-1.65.5 hdfs-2.7.3 httplib2-0.22.0 jsonpickle-3.4.2 lvis-0.5.3 numpy-1.26.4 object_detection-0.1 objsize-0.7.1 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 portalocker-3.2.0 pyarrow-hotfix-0.7 pydot-1.4.2 pymongo-4.15.5 pyparsing-2.4.7 redis-5.3.1 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-model-optimization-0.8.0 tensorflow_io-0.37.1 tf-models-official-2.19.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not make proto path relative: object_detection/photos/*.proto: No such file or directory\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.0 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJz91r3MQDV",
        "outputId": "9d12561f-be8c-4009-aa5c-b9603822370d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/162.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.69.0 requires protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<7.0.0.dev0,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-discoveryengine 0.13.12 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-dataproc 5.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-spanner 3.59.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-secret-manager 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-logging 3.12.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-appengine-logging 1.7.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.28.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.128.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-speech 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-trace 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.72.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-monitoring 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigtable 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-audit-log 0.4.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test API Installation"
      ],
      "metadata": {
        "id": "63uL2Mf3MSA-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "dZ_uvjd3MVMD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test SPI if everything was installed correctly\n",
        "!python models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKNO9TP2Mcbp",
        "outputId": "72995856-e60b-4ddb-a60b-50c56c40d58b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-07 23:48:08.946474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765151289.392511    3134 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765151289.469087    3134 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765151289.571338    3134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151289.571422    3134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151289.571435    3134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151289.571443    3134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-07 23:48:09.580457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/builders/model_builder.py\", line 23, in <module>\n",
            "    from object_detection.builders import anchor_generator_builder\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/builders/anchor_generator_builder.py\", line 26, in <module>\n",
            "    from object_detection.protos import anchor_generator_pb2\n",
            "ImportError: cannot import name 'anchor_generator_pb2' from 'object_detection.protos' (/usr/local/lib/python3.12/dist-packages/object_detection/protos/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y protobuf-compiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICGKBCOuPG5L",
        "outputId": "7936df63-5158-4905-a24e-b35c4ca404ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow 2 Detection Model Zoo\n",
        "import pathlib\n",
        "import zipfile\n",
        "import urllib\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "import math\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import important modules from Object Detection Model\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "L8CVGkhQMtGl",
        "outputId": "6af6774a-bd86-46b1-f882-4d77720eb34d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/usr/local/lib/python3.12/dist-packages/object_detection/protos/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-901585476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Import important modules from Object Detection Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0m_LABEL_OFFSET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/usr/local/lib/python3.12/dist-packages/object_detection/protos/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running these below 6 steps to tale care of the error getting from the above import\n",
        "!sudo apt-get -qq install protobuf-compiler python3-dev python3-pip\n",
        "!pip install tf_slim pycocotools lxml Cython contextlib2 pillow matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO75BThWPe7m",
        "outputId": "18728882-c24a-41bc-c63c-f4da56cf70e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/python3.10/python3.10-dev_3.10.12-1%7e22.04.11_amd64.deb  404  Not Found [IP: 91.189.91.82 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.12/dist-packages (21.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf_slim) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdiwvsioPtRh",
        "outputId": "e5db56ff-839e-4fe7-9244-17ce93302036"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yrsMGBrPxPG",
        "outputId": "252336e5-e2d0-440a-e109-62f8da38de91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOFrktjYP4gw",
        "outputId": "6121b925-e21d-41bf-b6f8-c855655d409b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.69.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.19.1)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.187.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: ai-edge-litert>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.0.3)\n",
            "Requirement already satisfied: tensorflow~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.7)\n",
            "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (43.0.3)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.11.4)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.20)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.65.5)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.25.1)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (25.0)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.15.5)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<7.0.0.dev0,>=3.20.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.32.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.15.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.25.0)\n",
            "Requirement already satisfied: beartype<0.22.0,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.21.0)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.7)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (1.4.9)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (4.60.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: backports.strenum in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (1.2.8)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.9.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.12/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.11)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: PyJWT>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (2.10.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.23)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (6.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.3)\n",
            "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: object_detection\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697325 sha256=f1c78545d8a6de906648c1bc10a128b9795d59184dca81c9d536b64c438f81d3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g5ydvzcn/wheels/93/ad/c5/62cdd10f6d842d66f3d05020591434c5aefd0cdea6bcd6f0ff\n",
            "Successfully built object_detection\n",
            "Installing collected packages: protobuf, object_detection\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "  Attempting uninstall: object_detection\n",
            "    Found existing installation: object_detection 0.1\n",
            "    Uninstalling object_detection-0.1:\n",
            "      Successfully uninstalled object_detection-0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed object_detection-0.1 protobuf-5.29.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI-ihJdHQGWa",
        "outputId": "2efa758e-a592-4fcf-be48-8e2c1400dd34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-07 23:58:27.906225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765151907.943917    5762 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765151907.959484    5762 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765151908.001034    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151908.001094    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151908.001099    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765151908.001103    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/builders/model_builder.py\", line 23, in <module>\n",
            "    from object_detection.builders import anchor_generator_builder\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/builders/anchor_generator_builder.py\", line 26, in <module>\n",
            "    from object_detection.protos import anchor_generator_pb2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/protos/anchor_generator_pb2.py\", line 14, in <module>\n",
            "    from object_detection.protos import flexible_grid_anchor_generator_pb2 as object__detection_dot_protos_dot_flexible__grid__anchor__generator__pb2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/object_detection/protos/flexible_grid_anchor_generator_pb2.py\", line 36, in <module>\n",
            "    _descriptor.FieldDescriptor(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/protobuf/descriptor.py\", line 621, in __new__\n",
            "    _message.Message._CheckCalledFromGeneratedFile()\n",
            "TypeError: Descriptors cannot be created directly.\n",
            "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
            "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
            " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
            " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
            "\n",
            "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "sPeNO4k7QQVG",
        "outputId": "55afcefd-479c-4ba3-9304-6d777b66803b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2747930041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0m_LABEL_OFFSET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/object_detection/protos/string_int_label_map_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mcreate_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_create_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   values=[\n\u001b[0;32m---> 33\u001b[0;31m     _descriptor.EnumValueDescriptor(\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UNSPECIFIED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, index, number, type, options, serialized_options, create_key)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 options=None, serialized_options=None, create_key=None):\n\u001b[0;32m--> 920\u001b[0;31m       \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CheckCalledFromGeneratedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m       \u001b[0;31m# There is no way we can build a complete EnumValueDescriptor with the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# given parameters (the name of the Enum is not known, for example).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q tf_slim pycocotools lxml Cython contextlib2 pillow matplotlib\n",
        "\n",
        "cd /content\n",
        "rm -rf models\n",
        "git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "cd /content/models/research\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n",
        "\n",
        "python object_detection/builders/model_builder_tf2_test.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "e_-cIUb8RJvo",
        "outputId": "e2076ee0-8f54-434b-aaf3-7e2f4c24de48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-4030594133.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4030594133.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install -q tf_slim pycocotools lxml Cython contextlib2 pillow matplotlib\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(download_url):\n",
        "\n",
        "    '''\n",
        "    Args:\n",
        "    download_url:  `model's download URL`\n",
        "    '''\n",
        "\n",
        "    # Extract model's name\n",
        "    zip_model = download_url.split('/')[-1]\n",
        "    model_name = zip_model.split('.')[0]\n",
        "\n",
        "    # Check if model directory already exists or not\n",
        "    if not os.path.exists(os.getcwd()+model_name):\n",
        "\n",
        "        # Download & Extract model.\n",
        "        urllib.request.urlretrieve(download_url , zip_model)\n",
        "        tar = tarfile.open(zip_model)\n",
        "        tar.extractall()\n",
        "        tar.close\n",
        "\n",
        "        # Remove tar file\n",
        "        os.remove(zip_model)\n",
        "\n",
        "        # Print Download Message\n",
        "        print(\"{} Model downloaded successfully!\".format(model_name))\n",
        "\n",
        "    # Load the model\n",
        "    model_path = pathlib.Path(model_name)/'saved_model'\n",
        "    model= tf.saved_model.load(str(model_path))\n",
        "\n",
        "    # Print Success message\n",
        "    print(\"{} Model Loaded Successfully!\".format(model_name))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Zb7_rblHM4bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove warnings\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Our Model dictionary\n",
        "model_url_dict = {\n",
        "\n",
        "    'EfficientDet': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "    'RetinaNet': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n",
        "    'MobileNet': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz',\n",
        "    'Faster-RCNN': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz'\n",
        "}"
      ],
      "metadata": {
        "id": "rwRyXoGxM-aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowload and save models in a directory with their proper names\n",
        "loaded_models = {}\n",
        "\n",
        "for key in model_url_dict.keys():\n",
        "  model = load_model(model_url_dict[key])\n",
        "  loaded_models[key] = model"
      ],
      "metadata": {
        "id": "dXKhNVDcNBKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can print the cateogory_index to see the index:class mapping.\n",
        "LABEL_TEXT_PATH = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(LABEL_TEXT_PATH, use_display_name=True)"
      ],
      "metadata": {
        "id": "sKXqtU_9NTpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to perform inference\n",
        "\n",
        "def run_inference(test_image_path, name , conf = 0.5): # Our confidence value is 0.5\n",
        "    '''\n",
        "    A function that uses saved model in our model_dict for inference.\n",
        "    Using saved models to predict on input images, we get a tensor object which we save in our **output_tensor** variable.\n",
        "    We then convert this tensor object into numpy arrays to plot our inferences.\n",
        "\n",
        "    To visualize our inferences we will use OpenCV and Matplotlib.\n",
        "\n",
        "    What does the output_tensor variable contains?\n",
        "    Our output_tensor is a tensor object variable which contains different information about our test images.\n",
        "    It contains number of detections, class_index, class_scores and etc. It uses a dictionary to map these\n",
        "    informations to their values.\n",
        "\n",
        "    Args:\n",
        "    name: This denotes to the name of model we are using. We will use model_dict to obtain model values for that model\n",
        "    image: Input image that we will run inference on.\n",
        "    conf: Threshold confidence from which we want our class scores to be higher for confirmation of an object. It has originally been set to 0.5.\n",
        "\n",
        "    Returns:\n",
        "    image: image with predictions visualized\n",
        "\n",
        "    '''\n",
        "    # Copy test image path in temporary variable\n",
        "    image = test_image_path[...,::-1]\n",
        "\n",
        "    # Retrieve our model from model_dict\n",
        "    detection_model = loaded_models[name]\n",
        "\n",
        "    # Get shape of our original image to resize our bbox to fit with original image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Resize our image\n",
        "    resized_image = cv2.resize(image,(640,640))\n",
        "\n",
        "    # The model requires a batch of images, so add an axis with `tf.newaxis`.\n",
        "    image_tensor = tf.convert_to_tensor(resized_image)\n",
        "    image_tensor = image_tensor[tf.newaxis,...]\n",
        "\n",
        "    # Run Inference\n",
        "    model_zoo = detection_model.signatures['serving_default']\n",
        "    output_tensor = model_zoo(image_tensor)\n",
        "\n",
        "    # Get total no. of detections in an image\n",
        "    num_detections = int(output_tensor.pop('num_detections'))\n",
        "\n",
        "    # Convert our output tensor to numpy\n",
        "    output_tensor = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_tensor.items()}\n",
        "    output_tensor['num_detections'] = num_detections\n",
        "\n",
        "    # Change type for our detection classes\n",
        "    output_tensor['detection_classes'] = output_tensor['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 0\n",
        "\n",
        "    # Use the TensorFlow visualization_utils.py to draw the bounding boxes along with the class labels and the confidences.\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                                image,\n",
        "                                output_tensor['detection_boxes'],\n",
        "                                output_tensor['detection_classes'] + label_id_offset,\n",
        "                                output_tensor['detection_scores'],\n",
        "                                category_index,\n",
        "                                use_normalized_coordinates=True,\n",
        "                                max_boxes_to_draw=100,\n",
        "                                min_score_thresh=conf,\n",
        "                                agnostic_mode=False)\n",
        "\n",
        "    # Return our annotated image\n",
        "    return image"
      ],
      "metadata": {
        "id": "-hRFBfjSNXlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Test Images"
      ],
      "metadata": {
        "id": "57yLRBM9NrF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, save_name):\n",
        "  url = url\n",
        "  if not os.path.exists(save_name):\n",
        "    file = requests.get(url)\n",
        "    open(save_name, 'wb').write(file.content)"
      ],
      "metadata": {
        "id": "BsJV2QmGNuJv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")"
      ],
      "metadata": {
        "id": "gGQk_PNBQwyK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL and Name of our test image folder\n",
        "test_images_url = 'https://www.dropbox.com/s/3qcb1l2nq95st46/Test_Images.zip?dl=1'\n",
        "test_images_zip = 'Test_Images.zip'\n",
        "\n",
        "# Download test images folder\n",
        "download_file(test_images_url , test_images_zip)\n",
        "\n",
        "# Extract the zip folder and remove the zip\n",
        "unzip(test_images_zip)\n",
        "\n",
        "folder_name = './Test_Images'\n",
        "# Load complete image file paths in a list\n",
        "image_paths = os.listdir(folder_name)\n",
        "image_paths = [os.path.join(folder_name,  img) for img in image_paths]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "OxsHEyYyRYKD",
        "outputId": "ec266352-06ef-412b-9c4f-cbf7926d8889"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'download_file' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2935065153.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Download test images folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_url\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_images_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Extract the zip folder and remove the zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'download_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "SScZeCL8Rchq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_image = image_paths[5]\n",
        "demo_image = cv2.imread(demo_image)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(demo_image[...,::-1]);plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "KMd11_-6RfX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference: EfficientDet\n",
        "\n",
        "# Run inference\n",
        "annotated_image = run_inference(demo_image.copy(), name='EfficientDet')\n",
        "\n",
        "# Display our annotated image in matplotlib\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(annotated_image);plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "SSraTl63Rg2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference: SSD MobileNet\n",
        "\n",
        "annoted_image = run_inference(demo_image.copy(), name='MobileNet')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(annoted_image); plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "qDiGbLmFRnDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference: RetinaNet\n",
        "\n",
        "annoted_image = run_inference(demo_image.copy(), name='RetinaNet')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(annoted_image); plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "9KwkKCSpR6eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference: Faster R-CNN\n",
        "\n",
        "annotated_image = run_inference(demo_image.copy(),name='Faster-RCNN')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(annotated_image);plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "LZXpAcR7SKcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all Models\n",
        "def compare_all_models(imagepath):\n",
        "\n",
        "    # Load the image.\n",
        "    image = cv2.imread(imagepath)\n",
        "\n",
        "    # Get all the model names.\n",
        "    model_names = list(loaded_models.keys())\n",
        "\n",
        "    # Set fig size, rows & cols.\n",
        "    plt.figure(figsize=[20,15])\n",
        "    columns = 2\n",
        "    rows = 2\n",
        "\n",
        "    # Take the image, perform precition by each model and display all 4 results in a 2x2 grid.\n",
        "    for i in range(0, len(model_names)):\n",
        "        annotated_img = run_inference(image.copy(), name = model_names[i])\n",
        "        plt.subplot(rows, columns, i+1);plt.imshow(annotated_img);\n",
        "        plt.title(\"Prediction Using {}\".format(model_names[i]));plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "GliYbnXSSNVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[0]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "6DgzaztZSVdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[1]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "Ze-fmImoSW4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[2]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "365JHDM8SYmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[3]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "l4XIRX5LSbXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[4]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "N8fuZ_MDSdES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[6]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "Heg-RqlISebo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[7]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "JBMHUhuKSgMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = image_paths[8]\n",
        "compare_all_models(test_image_path)"
      ],
      "metadata": {
        "id": "wsSmFH-vSiSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}